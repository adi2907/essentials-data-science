{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Basics for Data Analysis (30 mins)\n",
    "Python is an interpreted and object-oriented language, which means it executes code line-by-line and supports objects, classes, and methods. It is highly readable and simple, making it an excellent choice for beginners and data analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "# Python code can be executed directly without compilation\n",
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables, Data Types, and Basic Operations\n",
    "\n",
    "### Variables and Assignment\n",
    "Variables are containers for storing data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Alice True\n"
     ]
    }
   ],
   "source": [
    "# Assign values to variables\n",
    "x = 10\n",
    "name = \"Alice\"\n",
    "is_active = True\n",
    "\n",
    "# Print variables\n",
    "print(x, name, is_active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object-oriented: All variables in Python are objects\n",
    "\n",
    "x = 42\n",
    "print(x.real)  # Accessing attributes of the int object\n",
    "print(x + 10)  # Using methods/operators on an object\n",
    "print(x.__le__(50)) # accessing internal methods\n",
    "\n",
    "y = \"Hello\"\n",
    "print(y.upper())  # Accessing string methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "Python has various data types such as integers, floats, strings, booleans, and collections like lists and dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 5.9 Hello, Python! False [1, 2, 3, 4, 5] {'name': 'Alice', 'age': 25}\n"
     ]
    }
   ],
   "source": [
    "# Integer and Float\n",
    "age = 25\n",
    "height = 5.9\n",
    "\n",
    "# String\n",
    "greeting = \"Hello, Python!\"\n",
    "\n",
    "# Boolean\n",
    "is_valid = False\n",
    "\n",
    "# List\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "\n",
    "# Dictionary\n",
    "person = {\"name\": \"Alice\", \"age\": 25}\n",
    "\n",
    "print(age, height, greeting, is_valid, numbers, person)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python's flexibility as a weakly typed language allows operations between different data types without explicit type declarations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.9\n",
      "Hello, Python! Age is 25\n",
      "[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n",
      "Alice is 25 years old.\n",
      "False\n",
      "25 5.9 Hello, Python! False [1, 2, 3, 4, 5] {'name': 'Alice', 'age': 25}\n"
     ]
    }
   ],
   "source": [
    "# Variables with different types\n",
    "age = 25\n",
    "height = 5.9\n",
    "greeting = \"Hello, Python!\"\n",
    "is_valid = False\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "person = {\"name\": \"Alice\", \"age\": 25}\n",
    "\n",
    "# Implicit type conversion and operations\n",
    "print(age + height)  # Adds int and float: 25 + 5.9 -> 30.9\n",
    "print(greeting + \" Age is \" + str(age))  # Concatenates string and int\n",
    "print(numbers * 2)  # Duplicates the list: [1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n",
    "print(person[\"name\"] + \" is \" + str(person[\"age\"]) + \" years old.\")  # String manipulation\n",
    "print(bool(age) and is_valid)  # Combines int and bool in a logical operation: False\n",
    "\n",
    "# Display all variables\n",
    "print(age, height, greeting, is_valid, numbers, person)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loops and conditional statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### If-Else\n",
    "\n",
    "# Conditional statements\n",
    "x = 10\n",
    "if x > 5:\n",
    "    print(\"x is greater than 5\")\n",
    "else:\n",
    "    print(\"x is 5 or less\")\n",
    "\n",
    "\n",
    "### For Loop\n",
    "\n",
    "# Looping through a list\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "for num in numbers:\n",
    "    print(num)\n",
    "\n",
    "\n",
    "### While Loop\n",
    "\n",
    "# Loop until a condition is met\n",
    "count = 0\n",
    "while count < 5:\n",
    "    print(\"Count is\", count)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some interesting nuances in loops and specific data structures in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip: Merge two lists into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"name\", \"age\", \"city\"]\n",
    "values = [\"Alice\", 25, \"New York\"]\n",
    "\n",
    "result = dict(zip(keys, values))\n",
    "print(result)  # {'name': 'Alice', 'age': 25, 'city': 'New York'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehension: Elegant and concise iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squares = [x ** 2 for x in range(1, 6)]\n",
    "print(squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Example Using Enumerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the string into words\n",
    "text = \"Python is a great programming language.\"\n",
    "tokens = text.split()  # ['Python', 'is', 'a', 'great', 'programming', 'language.']\n",
    "\n",
    "# Assigning indices to tokens using enumerate\n",
    "tokenized = {index: token for index, token in enumerate(tokens)}\n",
    "\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set: Removing duplicates from a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1, 2, 3, 1, 2, 4, 5, 4, 6]\n",
    "\n",
    "# Use set to create a unique list\n",
    "unique_items = list(set(items))\n",
    "\n",
    "print(\"Original List:\", items)\n",
    "print(\"Unique List:\", unique_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for with else: Search for a specific file in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = \"/path/to/directory\"\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".txt\"):\n",
    "        print(f\"Found a text file: {file}\")\n",
    "        break\n",
    "else:\n",
    "    print(\"No text files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use of Range with For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Months of the year\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "# Use range to iterate through months\n",
    "for i in range(len(months)):\n",
    "    print(f\"Generating report for {months[i]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File and Directory Access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a file\n",
    "with open('example.txt', 'w') as file:\n",
    "    file.write(\"Hello, this is a test file.\")\n",
    "\n",
    "# Reading from a file\n",
    "with open('example.txt', 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Directory Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# List files and directories in the current directory\n",
    "print(os.listdir('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Removing Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory\n",
    "os.mkdir('test_directory')\n",
    "\n",
    "# Remove a directory\n",
    "os.rmdir('test_directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Directory Structure with Tree Command\n",
    "To view the directory structure in your terminal, you can use the `tree` command (install it if not available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Arrays\n",
    "NumPy arrays are more efficient than Python lists for numerical operations. You can create arrays using np.array().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Creating a NumPy array\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "print(\"Array:\", array)\n",
    "print(\"Type:\", type(array))\n",
    "\n",
    "# 1D Array\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "print(\"1D Array:\", arr_1d)\n",
    "\n",
    "# 2D Array\n",
    "arr_2d = np.array([[1, 2], [3, 4]])\n",
    "print(\"2D Array:\\n\", arr_2d)\n",
    "\n",
    "# 3D Array\n",
    "arr_3d = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(\"3D Array:\\n\", arr_3d)\n",
    "\n",
    "\n",
    "# Arithmetic with numpy arrays\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "# Arithmetic operations\n",
    "print(\"Addition:\", a + b)\n",
    "print(\"Multiplication:\", a * b)\n",
    "print(\"Scalar Multiplication:\", a * 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "# Access specific element\n",
    "print(\"Element at (0,1):\", arr[0, 1])\n",
    "\n",
    "# Slice rows and columns\n",
    "print(\"First row:\", arr[0, :])\n",
    "print(\"First column:\", arr[:, 0])\n",
    "\n",
    "# Modify elements\n",
    "arr[1, 1] = 99\n",
    "print(\"Modified Array:\\n\", arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing arrays\n",
    "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original Array:\\n\", arr)\n",
    "print(\"Transposed Array:\\n\", arr.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some musings on speed of numpy\n",
    "\n",
    "NumPy is significantly faster than Python's list and loop-based operations. The main benefit comes from vectorization, which eliminates the need for explicit loops by performing element-wise operations directly, and parallel computing capabilities, where NumPy leverages optimized, low-level C and Fortran libraries to perform operations efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python list addition took: 0.02499 seconds\n",
      "NumPy array addition took: 0.00071 seconds\n"
     ]
    }
   ],
   "source": [
    "# comparing array speeds of numpy versus regular python operations\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Generate data\n",
    "size = 1_000_000\n",
    "list1 = list(range(size))\n",
    "list2 = list(range(size))\n",
    "\n",
    "array1 = np.array(list1)\n",
    "array2 = np.array(list2)\n",
    "\n",
    "# Using Python lists\n",
    "start_time = time.time()\n",
    "result_list = [x + y for x, y in zip(list1, list2)]\n",
    "end_time = time.time()\n",
    "print(f\"Python list addition took: {end_time - start_time:.5f} seconds\")\n",
    "\n",
    "# Using NumPy arrays\n",
    "start_time = time.time()\n",
    "result_array = array1 + array2\n",
    "end_time = time.time()\n",
    "print(f\"NumPy array addition took: {end_time - start_time:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.197183098591545\n"
     ]
    }
   ],
   "source": [
    "speed_upgrade = 0.02499/0.00071\n",
    "print(speed_upgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A practical use of NumPy is to calculate similarity among various vectors. We'll cover this more deeply later on\n",
    "# It is the fastest way to compute similarity for vectors derived from large 'embeddings' generated by various text sources, \n",
    "# such as word embeddings, sentence embeddings, or document embeddings in natural language processing (NLP). \n",
    "# NumPy's vectorized operations, like dot product and normalization, make it highly efficient for comparing embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity (Lists): 0.75007, Time: 0.10440 seconds\n",
      "Cosine Similarity (NumPy): 0.75007, Time: 0.00126 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Generate large random arrays\n",
    "size = 1_000_000\n",
    "vec1 = np.random.rand(size)\n",
    "vec2 = np.random.rand(size)\n",
    "\n",
    "# Using Python lists for cosine similarity\n",
    "vec1_list = vec1.tolist()\n",
    "vec2_list = vec2.tolist()\n",
    "\n",
    "def cosine_similarity_lists(v1, v2):\n",
    "    dot_product = sum(x * y for x, y in zip(v1, v2))\n",
    "    norm_v1 = math.sqrt(sum(x ** 2 for x in v1))\n",
    "    norm_v2 = math.sqrt(sum(y ** 2 for y in v2))\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "# Using NumPy for cosine similarity\n",
    "def cosine_similarity_numpy(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm_v1 * norm_v2)\n",
    "\n",
    "# Measure time for Python lists\n",
    "start_time = time.time()\n",
    "cos_sim_list = cosine_similarity_lists(vec1_list, vec2_list)\n",
    "end_time = time.time()\n",
    "print(f\"Cosine Similarity (Lists): {cos_sim_list:.5f}, Time: {end_time - start_time:.5f} seconds\")\n",
    "\n",
    "# Measure time for NumPy\n",
    "start_time = time.time()\n",
    "cos_sim_numpy = cosine_similarity_numpy(vec1, vec2)\n",
    "end_time = time.time()\n",
    "print(f\"Cosine Similarity (NumPy): {cos_sim_numpy:.5f}, Time: {end_time - start_time:.5f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.85714285714286\n"
     ]
    }
   ],
   "source": [
    "speed_upgrade = 0.10440/0.00126\n",
    "print(speed_upgrade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Weekly sales data (rows: weeks, columns: categories)\n",
    "sales_data = np.array([\n",
    "    [150, 200, 250, 300, 350],\n",
    "    [160, 210, 240, 310, 360],\n",
    "    [155, 220, 260, 290, 370],\n",
    "    [165, 230, 270, 280, 340],\n",
    "    [170, 190, 220, 310, 330],\n",
    "    [180, 195, 245, 320, 310],\n",
    "    [175, 185, 235, 305, 325],\n",
    "    [190, 215, 250, 315, 345],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise for numpy\n",
    "\n",
    "Shape and Data Overview: Print the shape of the array and the total sales for the store (sum of all elements).\n",
    "\n",
    "Slicing Data: Extract the sales data for the last 4 weeks and first 3 product categories.\n",
    "\n",
    "Category-wise Totals: Calculate the total sales for each product category across all weeks (hint: sum along the correct axis).\n",
    "\n",
    "Find the Week with the Highest Sales: Identify the week (row index) with the highest total sales.\n",
    "\n",
    "Filter by Threshold: Print the weeks where sales of product category 3 (index 2) exceeded 250.\n",
    "\n",
    "Normalize Sales Data: Normalize the sales data by dividing each element by the maximum sales recorded in any category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hints\n",
    "Hint 1: sales_data.shape gives the dimensions of the array.\n",
    "Hint 2: Use sales_data[-4:, :3] to slice the last 4 rows and first 3 columns.\n",
    "Hint 3: Use np.sum along axis for category-wise totals.\n",
    "Hint 4: Use np.argmax and np.sum to find the index of the row with the highest sales.\n",
    "Hint 5: Use Boolean indexing\n",
    "Hint 6: Use sales_data / np.max(sales_data) for normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Pandas is the big daddy of data manipulation, offering powerful tools for cleaning, transforming, and analyzing large datasets with ease. Its intuitive DataFrame and Series structures simplify handling tabular data, while built-in functions enable efficient filtering, grouping, and aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental unit of Pandas is Series and Dataframe\n",
    "\n",
    "Series:\n",
    "\n",
    "A one-dimensional labeled array capable of holding any data type (integer, string, float, etc.).\n",
    "\n",
    "Similar to a column in a spreadsheet or database table.\n",
    "\n",
    "DataFrame:\n",
    "\n",
    "A two-dimensional labeled data structure with columns of potentially different types.\n",
    "\n",
    "Think of it as a spreadsheet or SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series\n",
    "import pandas as pd\n",
    "data = [10, 20, 30, 40]\n",
    "series = pd.Series(data, name='Numbers')\n",
    "print(\"Series\")\n",
    "print(series)\n",
    "print(\"********\")\n",
    "\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Score': [85, 90, 78]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's create some sample data to work with. We'll generate sales data\n",
    "that includes dates, products, regions, and various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate sample sales data\n",
    "np.random.seed(42)\n",
    "n_rows = 300\n",
    "\n",
    "# Sales Data\n",
    "dates = pd.date_range('2023-01-01', periods=n_rows)\n",
    "products = ['Laptop', 'Phone', 'Tablet', 'Watch']\n",
    "regions = ['North', 'South', 'East', 'West']\n",
    "\n",
    "sales_data = {\n",
    "    'Date': dates,\n",
    "    'Product': np.random.choice(products, n_rows),\n",
    "    'Region': np.random.choice(regions, n_rows),\n",
    "    'Units': np.random.randint(1, 50, n_rows),\n",
    "    'Price': np.random.uniform(200, 2000, n_rows).round(2),\n",
    "    'Customer_Rating': np.random.uniform(3, 5, n_rows).round(1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales = pd.DataFrame(sales_data)\n",
    "#df_sales.head(5)\n",
    "# create a new columnn (series) as function of other values\n",
    "df_sales['Total_Sales'] = df_sales['Units'] * df_sales['Price']\n",
    "df_sales.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate customer data\n",
    "customer_data = {\n",
    "    'Region': regions,\n",
    "    'Regional_Manager': ['John Smith', 'Emma Davis', 'Michael Chen', 'Sarah Wilson'],\n",
    "    'Target_Revenue': np.random.uniform(100000, 500000, 4).round(2)\n",
    "}\n",
    "df_customers = pd.DataFrame(customer_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most useful functions of pandas is ease of loading data from various sources - csv,xlsx and sql as well. You can checkout all the various ways pandas can read the files. Also Pandas can read files in sizes exceeding several GB (Excel cops out in a few hundred MBs). Similarly you can write back the data to csv easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.to_csv('sales_data.csv',index=False)\n",
    "df_customers.to_csv('customter_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Basic Data Exploration ===\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_sales.head())\n",
    "print(\"\\nDataset info:\")\n",
    "print(df_sales.info())\n",
    "print(\"\\nSummary statistics:\")\n",
    "print(df_sales.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Filtering\n",
    "print(\"\\n=== Data Filtering ===\")\n",
    "high_value_sales = df_sales[df_sales['Total_Sales'] > df_sales['Total_Sales'].mean()]\n",
    "print(\"\\nHigh value sales (above mean):\")\n",
    "print(high_value_sales.head())\n",
    "\n",
    "# Filter multiple conditions\n",
    "laptop_north = df_sales[(df_sales['Product'] == 'Laptop') & (df_sales['Region'] == 'North')]\n",
    "print(\"\\nLaptop sales in North region:\")\n",
    "print(laptop_north.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aggregation\n",
    "One of the principal requirements in Pandas is to group by some parameter. E.g. you want to summarise sales by region, then you will group by the region. It is very similar to GROUPBY in sql for those who have a backgraound in DBMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sales by region:\n",
      "            min       max         sum\n",
      "Region                               \n",
      "East     839.65  82615.72  2080746.82\n",
      "North    638.44  75718.40  1838729.69\n",
      "South   2714.01  83102.88  2043672.52\n",
      "West     736.33  84279.51  2687353.85\n"
     ]
    }
   ],
   "source": [
    "region_sales = df_sales.groupby('Region')['Total_Sales'].agg(['min','max','sum'])\n",
    "print(\"\\nSales by region:\")\n",
    "print(region_sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas dataframes and series are actually built on numpy hence they are so fast. Below we will do some operations which combine dataframes and numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to numpy array\n",
    "sales_array = region_sales['min','max','sum'].to_numpy()\n",
    "\n",
    "# Calculate the mean across columns\n",
    "print(\"Mean across columns\")\n",
    "np.mean(sales_array,axis=1)\n",
    "\n",
    "# Find the max sum across all regions\n",
    "print(\"Max sum across regions\")\n",
    "print(np.max(sales_array[:,2]))\n",
    "\n",
    "# Normalized sum brings all sum values between 0 and 1\n",
    "min_sum = region_sales['sum'].min()\n",
    "max_sum = region_sales['sum'].max()\n",
    "region_sales['normalized_sum'] = (region_sales['sum'] - min_sum)/(max_sum - min_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_performance = df_sales.groupby('Product').agg({\n",
    "    'Units': 'sum',\n",
    "    'Total_Sales': 'sum',\n",
    "    'Customer_Rating': 'mean'\n",
    "}).round(2)\n",
    "print(\"\\nProduct performance:\")\n",
    "print(product_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Time Series Analysis\n",
    "print(\"\\n=== Time Series Analysis ===\")\n",
    "monthly_sales = df_sales.set_index('Date').resample('M')['Total_Sales'].sum()\n",
    "print(\"\\nMonthly sales:\")\n",
    "print(monthly_sales)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very useful feature of Pandas is 'merge' which is similar to 'JOIN' in SQL. Multiple files with a single common attribute can be merged in this way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Data Merging ===\")\n",
    "merged_df = df_sales.merge(df_customers, on='Region', how='left')\n",
    "print(\"\\nMerged data:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods and Lambda methods. \n",
    "I had held off introducing methods or functions till now since this is typically the cornerstone of any language. For data analysis, methods and anonymous methods (or lambda as we call them) become equally important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Product', 'Region', 'Units', 'Price', 'Customer_Rating',\n",
       "       'Total_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sales.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Product</th>\n",
       "      <th>Region</th>\n",
       "      <th>Units</th>\n",
       "      <th>Price</th>\n",
       "      <th>Customer_Rating</th>\n",
       "      <th>Total_Sales</th>\n",
       "      <th>sales_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>North</td>\n",
       "      <td>45</td>\n",
       "      <td>940.17</td>\n",
       "      <td>3.7</td>\n",
       "      <td>42307.65</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>Watch</td>\n",
       "      <td>North</td>\n",
       "      <td>32</td>\n",
       "      <td>1285.01</td>\n",
       "      <td>3.1</td>\n",
       "      <td>41120.32</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>Laptop</td>\n",
       "      <td>East</td>\n",
       "      <td>30</td>\n",
       "      <td>687.72</td>\n",
       "      <td>3.2</td>\n",
       "      <td>20631.60</td>\n",
       "      <td>Med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>South</td>\n",
       "      <td>47</td>\n",
       "      <td>439.73</td>\n",
       "      <td>3.2</td>\n",
       "      <td>20667.31</td>\n",
       "      <td>Med</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>South</td>\n",
       "      <td>35</td>\n",
       "      <td>337.16</td>\n",
       "      <td>4.7</td>\n",
       "      <td>11800.60</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date Product Region  Units    Price  Customer_Rating  Total_Sales  \\\n",
       "0 2023-01-01  Tablet  North     45   940.17              3.7     42307.65   \n",
       "1 2023-01-02   Watch  North     32  1285.01              3.1     41120.32   \n",
       "2 2023-01-03  Laptop   East     30   687.72              3.2     20631.60   \n",
       "3 2023-01-04  Tablet  South     47   439.73              3.2     20667.31   \n",
       "4 2023-01-05  Tablet  South     35   337.16              4.7     11800.60   \n",
       "\n",
       "  sales_category  \n",
       "0           High  \n",
       "1           High  \n",
       "2            Med  \n",
       "3            Med  \n",
       "4            Low  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Methods is defined with 'def' keyword\n",
    "\n",
    "def categorize_sales(sales:int) -> str: # Typically take an argument, do transformation and return an output\n",
    "    if sales>25000:\n",
    "        return 'High'\n",
    "    elif sales >=15000 and sales <25000:\n",
    "        return 'Med'\n",
    "    else:\n",
    "        return 'Low'\n",
    "    \n",
    "\n",
    "df_sales['sales_category'] = df_sales['Total_Sales'].apply(categorize_sales)\n",
    "df_sales.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another important notation is the lambda notation where you write functions inline to transform the data\n",
    "# x is the input parameter or argument\n",
    "\n",
    "df_sales.drop(columns='sales_category')\n",
    "\n",
    "df_sales['sales_category'] = df_sales['Total_Sales'].apply(\n",
    "    lambda x: 'High' if x>25000 else 'Med' if x >=15000 else 'Low')\n",
    "df_sales.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Product', 'Region', 'Units', 'Price', 'Customer_Rating',\n",
      "       'Total_Sales', 'sales_category'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_sales.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining some concepts - Groupby, Filter, lambda etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Among high sales_category entries, which region is giving the maximum sales\n",
    "\n",
    "# first filter the dataframe\n",
    "df_sales = df_sales[df_sales['sales_category']=='High']\n",
    "# then apply groupby and sum\n",
    "max_sum_per_region = df_sales.groupby('Region')['Total_Sales'].sum()\n",
    "print(max_sum_per_region) # Groupby will transform the dataframe into a series with the index as region (since we grouped by region)\n",
    "max_sum_region = max_sum_per_region.idxmax()\n",
    "print(max_sum_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average price per product\n",
    "avg_price_per_product = df_sales.groupby('Product')['Price'].mean()\n",
    "print(avg_price_per_product) # This gives a series where Product is the index and mean price is the value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate profit margin using Lambda\n",
    "# Add a cost column\n",
    "df_sales['Cost'] = df_sales['Price']*np.random.uniform(0.6,0.8,size=len(df_sales))\n",
    "# Add Profit margin column using lambda\n",
    "df_sales['Profit_Margin'] = df_sales.apply(lambda row: ((row['Price']-row['Cost'])/row['Price'])*100,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finally we have covered essential Python concepts starting from basic data types and operations, progressing through advanced features like list comprehension, file handling, and directory management. The NumPy section demonstrated its power for numerical computations. Although you won't use numpy as much as Pandas  in data science. For Pandas we have laid the groundwork for data manipulation and analysis, emphasizing its fundamental structures (Series and DataFrame) and difference functions which can be applied to the tabular data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
